{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Talos Example with moving foot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.compat.v1 as tf1\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "import tf_robot_learning as rl\n",
    "import tf_robot_learning.distributions as ds\n",
    "import os, time\n",
    "from tf_robot_learning import kinematic as tk\n",
    "\n",
    "from IPython.core import display\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Define and Train GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf1.InteractiveSession()\n",
    "tf1.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define robot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urdf = tk.urdf_from_file(rl.datapath + '/urdf/talos_reduced.urdf');\n",
    "display.clear_output()\n",
    "\n",
    "#list of end-effector\n",
    "tips = OrderedDict({\n",
    "    'r_gripper'\t: 'gripper_right_base_link',\n",
    "    'l_gripper'\t: 'gripper_left_base_link',\n",
    "    'r_foot' \t: 'right_sole_link',\n",
    "    'l_foot' \t: 'left_sole_link',\n",
    "})\n",
    "\n",
    "#define the robot as a kinematic chain, loaded from urdf\n",
    "chain_names = ['r_gripper', 'l_gripper', 'r_foot', 'l_foot'] \n",
    "chain = tk.ChainDict({\n",
    "    name: tk.kdl_chain_from_urdf_model(urdf, 'base_link', tip=tip)\n",
    "    for name, tip in tips.items()\n",
    "})\n",
    "\n",
    "#define the default position and orientation of the end-effector\n",
    "ee = OrderedDict({\n",
    "        'l_gripper': [0.  , 0.29, 0.8 , 1.  , 0.  , 0.  , 0.  , 1.  , 0.  , 0.  , 0.  ,1.  ],\n",
    "        'r_gripper': [0.  , -0.29, 0.8 , 1.  , 0.  , 0.  , 0.  , 1.  , 0.  , 0.  , 0.  ,1.  ],\n",
    "        'l_foot': [-0.02,  0.09, -0.  ,  1.  ,  0.  ,  0.  ,  0.  ,  1.  ,  0.  , 0.  ,  0.  ,  1.  ],\n",
    "        'r_foot': [-0.02,  -0.09, -0.  ,  1.  ,  0.  ,  0.  ,  0.  ,  1.  ,  0.  , 0.  ,  0.  ,  1.  ],\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def param_to_joint_pos(x):\n",
    "    \"\"\"\n",
    "    convert the config parameter x to full robot configurations: joint angles, base position and orientation\n",
    "    \"\"\"\n",
    "    return x[..., :chain.nb_joint],\\\n",
    "        tf.concat([x[..., chain.nb_joint:chain.nb_joint+3]], -1),\\\n",
    "        tk.rotation.rpy(tf.zeros_like(x[..., -3:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def q_augmented(q):\n",
    "    \"\"\" Define augmented data transformations: (joint_angles, right foot pose, and left foot pose)\"\"\"\n",
    "    _q, _p, _m = param_to_joint_pos(q)\n",
    "    return tf.concat([\n",
    "            q,\n",
    "            chain.xs(_q, floating_base=(_p, _m), name='r_foot')[:, -1],\n",
    "            chain.xs(_q, floating_base=(_p, _m), name='l_foot')[:, -1]\n",
    "        ], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def q_target(q):\n",
    "    \"\"\" Extract the target\"\"\"\n",
    "    _q, _p, _m = param_to_joint_pos(q)\n",
    "    return tf.concat( # orientation of each foot\n",
    "            [chain.xs(_q, floating_base=(_p, _m), name=name)[:, -1, :3] for name in chain_names]\n",
    "            , -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def q_foot_ori(q):\n",
    "    \"\"\" Extract the foot orientation \"\"\"\n",
    "    _q, _p, _m = param_to_joint_pos(q)\n",
    "    return tf.concat( # position of each end-effector\n",
    "            [chain.xs(_q, floating_base=(_p, _m), name=name)[:, -1, 3:] for name in chain_names[2:]]\n",
    "            , -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get mini batch\n",
    "def get_batch(_batch_size=30, cut=None, augmented=True):\n",
    "    if cut is not None: idx = np.random.randint(0, cut, _batch_size)\n",
    "    else: idx = np.random.randint(0, data_augmented.shape[0]-1, _batch_size)\n",
    "    if augmented: return data_augmented[idx]\n",
    "    else: return data[idx]\n",
    "    \n",
    "def get_target_batch(_batch_size=30, cut=None):\n",
    "    if cut is not None: idx = np.random.randint( 0, cut, _batch_size)\n",
    "    else: idx = np.random.randint(0, data_augmented.shape[0]-1, _batch_size)\n",
    "    return data_target[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "q_eval = tf1.placeholder(tf.float32, (None, chain.nb_joint + 3))\n",
    "\n",
    "q_augmented_eval = q_augmented(q_eval)\n",
    "q_target_eval = q_target(q_eval)\n",
    "q_foot_ori_eval = q_foot_ori(q_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the dataset\n",
    "data = np.load('data/data_two_feet_manual.npy')\n",
    "# compute data through these transformations\n",
    "data_augmented = q_augmented_eval.eval({q_eval: data})\n",
    "data_target = q_target_eval.eval({q_eval: data})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Network Parameters\n",
    "joint_dim = chain.nb_joint + 3 # the configuration consists of nb_joint= 28 joint angles and 3 base position\n",
    "latent_dim = 30 # dimension of noise\n",
    "N_net = 2\n",
    "target_dim = 12  # size of the target\n",
    "augmented_dim = 2 * 12 + joint_dim # size of augmented data (joint angles + poses of both foot)\n",
    "\n",
    "n_input = latent_dim + target_dim #dimension of the input to the generator\n",
    "batch_size = tf1.placeholder(tf.int32, ())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_nn = rl.nn.MLP(\n",
    "    n_input=n_input, n_output=joint_dim, n_hidden=[200, 200],\n",
    "    act_fct=tf.nn.relu, batch_size_svi=N_net\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the generator input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# noise to feed generator\n",
    "eps_var = tf1.placeholder(tf.float32, ())\n",
    "eps = tf.random.normal([tf.cast(batch_size/N_net, tf.int32), latent_dim], \n",
    "    dtype=tf.float32, mean=0., stddev=eps_var, name='epsilon')\n",
    "\n",
    "#the input to generator = noise + target\n",
    "batch_target = tf1.placeholder(tf.float32, (None, target_dim))\n",
    "eps_conc = tf.concat([eps, batch_target], axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define output transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_q = tf.reshape(gen_nn.pred(eps_conc) + tf.constant(chain.mean_pose + [0,0,1.08])[None], (-1, joint_dim))\n",
    "\n",
    "samples_qq, samples_p, samples_m = param_to_joint_pos(samples_q)\n",
    "samples_links, _, samples_com = chain.xs(samples_qq, floating_base=(samples_p, samples_m), get_links=True)\n",
    "\n",
    "samples_augmented = q_augmented(samples_q)\n",
    "samples_target = q_target(samples_q)\n",
    "samples_foot_ori = q_foot_ori(samples_q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discriminator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "discr_nn = rl.nn.MLP(\n",
    "    n_input=augmented_dim, n_output=1, n_hidden=[40, 40],\n",
    "    act_fct=tf.nn.relu\n",
    ")\n",
    "\n",
    "#batch data\n",
    "batch_x = tf1.placeholder(tf.float32, (None, augmented_dim))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define loss functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Main loss functions (discriminator vs generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "d_fake = discr_nn.pred(samples_augmented)[:, 0]\n",
    "d_true = discr_nn.pred(batch_x)[:, 0]\n",
    "\n",
    "#discriminator loss function\n",
    "loss_d = tf.nn.sigmoid_cross_entropy_with_logits(labels=tf.ones_like(d_true), logits=d_true) + \\\n",
    "        tf.nn.sigmoid_cross_entropy_with_logits(labels=tf.zeros_like(d_fake), logits=d_fake)\n",
    "loss_d = tf.reduce_sum(loss_d)\n",
    "\n",
    "#generator (basic) loss function\n",
    "loss = tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "    labels=tf.ones_like(d_fake), logits=d_fake)\n",
    "loss = tf.reduce_sum(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Target loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_target_std = tf1.placeholder(tf.float32, ()) \n",
    "\n",
    "p_target = ds.MultivariateNormalFullCovariance(\n",
    "    tf.reshape(tf.ones((N_net, 1,1))*batch_target,(-1, target_dim)), p_target_std**2 * tf.eye(target_dim)\n",
    ")\n",
    "\n",
    "loss_target = tf.reduce_sum(-p_target.log_prob(samples_target))\n",
    "lmbda_target = tf1.placeholder(tf.float32, ())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Foot orientation loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "foot_ori_dim = 18\n",
    "batch_foot_ori = tf1.placeholder(tf.float32, (None, foot_ori_dim))\n",
    "\n",
    "# define a Gaussian distribution that should be tracked by the system\n",
    "p_foot_ori_std = tf1.placeholder(tf.float32, ()) \n",
    "\n",
    "p_foot_ori = ds.MultivariateNormalFullCovariance(\n",
    "    tf.reshape(tf.ones((N_net, 1,1))*batch_foot_ori,(-1, foot_ori_dim)), p_foot_ori_std**2 * tf.eye(foot_ori_dim)\n",
    ")\n",
    "\n",
    "loss_foot_ori = tf.reduce_sum(-p_foot_ori.log_prob(samples_foot_ori))\n",
    "lmbda_foot_ori = tf1.placeholder(tf.float32, ())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Constraints cost: COM and joint limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#joint limit\n",
    "base_pos_limits = np.array([[-0.1, -0.1, 0.6],[0.1, 0.1, 1.4] ]).T\n",
    "config_limits = np.concatenate([chain.joint_limits, base_pos_limits], axis=0)\n",
    "joint_limits = tf.constant(config_limits, dtype=tf.float32)\n",
    "joint_limits_std = 0.05\n",
    "joint_limits_temp = 1.\n",
    "\n",
    "joint_limits_exp = ds.SoftUniformNormalCdf(\n",
    "    low=joint_limits[:, 0],\n",
    "    high=joint_limits[:, 1],\n",
    "    std=joint_limits_std,\n",
    "    temp=joint_limits_temp,\n",
    "    reduce_axis=-1\n",
    ")\n",
    "\n",
    "joint_limit_constraints = tf.reduce_mean(-joint_limits_exp.log_prob(samples_q[:,:chain.nb_joint+3]))\n",
    "\n",
    "\n",
    "#COM\n",
    "com_limits = 0.1\n",
    "com_limits_std = 0.01\n",
    "\n",
    "com_limits_exp = ds.SoftUniformNormalCdf(\n",
    "    low=-com_limits,\n",
    "    high=com_limits,\n",
    "    std=com_limits_std,\n",
    "    temp=1.,\n",
    "    reduce_axis=-1\n",
    ")\n",
    "\n",
    "com_xy = samples_com[:, :2]\n",
    "center_feet = tf.reduce_mean([\n",
    "        samples_links['r_foot'][:, -1, :2], \n",
    "        samples_links['l_foot'][:, -1, :2]\n",
    "        ], axis=0)\n",
    "\n",
    "cost_constraints = tf.reduce_mean(-com_limits_exp.log_prob(com_xy - center_feet))\n",
    "lmbda_constraints = tf1.placeholder(tf.float32, ())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overall loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_gen = loss +  lmbda_target * loss_target + lmbda_foot_ori*loss_foot_ori + lmbda_constraints * (cost_constraints+joint_limit_constraints) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "rate = tf1.placeholder(tf.float32, ())\n",
    "opt = tf1.train.AdamOptimizer\n",
    "\n",
    "optimizer = opt(learning_rate=rate)\n",
    "optimizer_d = opt(learning_rate=rate)\n",
    "\n",
    "train = optimizer.minimize(loss_gen, var_list=gen_nn.vec_weights)\n",
    "train_d = optimizer_d.minimize(loss_d, var_list=discr_nn.vec_weights)\n",
    "\n",
    "# Initialize the variables (i.e. assign their default value)\n",
    "init = tf1.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_target_new_batch(_batch_size):\n",
    "    return np.random.multivariate_normal(_targets_m, np.diag(_targets_v ** 2), (_batch_size, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_batch_size = 40\n",
    "_targets_m = np.concatenate([ee[name][:3] for name in chain_names], 0) # mean target\n",
    "_batch_foot_ori = np.tile(np.eye(3).flatten(), (int(_batch_size/N_net),2)).reshape(int(_batch_size/N_net),-1)\n",
    "\n",
    "_targets_m = np.concatenate([ee[name][:3] for name in chain_names], 0) # mean target\n",
    "_targets_v = np.array([0.5] * 3 + [0.5] * 3 + [0.2] * 2 + [0.] +  [0.2] * 2 + [0.]  )  # variance"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "alpha = .4\n",
    "for i in range(10000):\n",
    "    try:\n",
    "        for j in range(5):\n",
    "            # train discriminative_network\n",
    "            _x = get_batch(cut=8000, _batch_size=_batch_size)\n",
    "            \n",
    "            feed_dict = {\n",
    "                lmbda_target: .3,\n",
    "                lmbda_foot_ori: .05,\n",
    "                lmbda_constraints: 1.,\n",
    "                eps_var: 1.,\n",
    "                p_target_std: 0.01,\n",
    "                p_foot_ori_std: 0.01,\n",
    "                batch_x: _x,\n",
    "                batch_size: _batch_size,\n",
    "                rate : 0.002 * alpha,\n",
    "            }\n",
    "            \n",
    "            # from data\n",
    "            feed_dict[batch_target] = get_target_new_batch(_batch_size=int(_batch_size/N_net))\n",
    "\n",
    "            _ = sess.run([train_d], feed_dict=feed_dict)\n",
    "        \n",
    "        feed_dict[rate] = .001 * alpha\n",
    "        feed_dict[batch_foot_ori] = _batch_foot_ori\n",
    "        \n",
    "        # train generative_network\n",
    "        _,  _loss, _loss_d,  _loss_target, _loss_constraints = sess.run(\n",
    "            [train, loss, loss_d,  loss_target, cost_constraints], feed_dict=feed_dict)\n",
    "        \n",
    "        if not i % 10:\n",
    "            display.clear_output(wait=True)\n",
    "            print('Step %i\\t, loss gen %f, loss disc %f,  loss target %f, loss constraints %f' % (i, _loss, _loss_d ,_loss_target, _loss_constraints))\n",
    "    except KeyboardInterrupt:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To save model"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "saver = tf1.train.Saver()\n",
    "\n",
    "save_path = saver.save(sess, \"data/talos_foot_moved_with_data_ensemble2.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver = tf1.train.Saver()\n",
    "saver.restore(sess, \"data/talos_foot_moved_with_data_ensemble2.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the generated samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "_batch_size = 20\n",
    "feed_dict={batch_size: _batch_size, eps_var:1.}\n",
    "feed_dict[batch_target] = get_target_new_batch(_batch_size=int(_batch_size/N_net))\n",
    "\n",
    "_links, _com , _b_targets = sess.run(\n",
    "[samples_links, samples_com, batch_target], feed_dict\n",
    ")\n",
    "\n",
    "fig, ax = plt.subplots(ncols=2)\n",
    "\n",
    "for i in range(2):\n",
    "    dim = [i, 2]\n",
    "    chain.plot(\n",
    "            _links, feed_dict={}, ax=ax[i],\n",
    "            dim=dim, alpha=0.2, color='k'\n",
    "        )    \n",
    "    ax[i].plot(_com[0, dim[0]], _com[0, dim[1]], 'bx')\n",
    "    \n",
    "    for j, name in enumerate(chain_names):\n",
    "        ax[i].plot(_b_targets[:, j*3 + dim[0]], _b_targets[:, j*3 + dim[1]], 'rx', color='orangered')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from_dataset = 0\n",
    "n = 10\n",
    "\n",
    "_targets_m = np.concatenate([ee[name][:3] for name in chain_names], 0) # mean target\n",
    "_targets_v = np.array([0.3] * 3 + [0.3]*3 +  [0.1]*2 + [0.] + [0.1] * 2 + [0.]  )  # variance\n",
    "\n",
    "if from_dataset: \n",
    "    _targets = get_target_batch(cut=10000, _batch_size=1) * np.ones((int(n/N_net), 1))\n",
    "else:\n",
    "    _targets = np.random.multivariate_normal(_targets_m, np.diag(_targets_v ** 2), (1, )) * np.ones((int(n/N_net), 1))\n",
    "\n",
    "feed_dict={batch_size: n, batch_target: _targets, eps_var:.01}\n",
    "\n",
    "\n",
    "_links, _com , _b_targets, _samples_q = sess.run(\n",
    "    [samples_links, samples_com, batch_target, samples_q], \n",
    "    feed_dict)\n",
    "\n",
    "fig, ax = plt.subplots(ncols=2, figsize=(12,8))\n",
    "\n",
    "for i in range(2):\n",
    "    dim = [i, 2]\n",
    "    chain.plot(\n",
    "            _links, feed_dict={}, ax=ax[i],\n",
    "            dim=dim, alpha=0.2, color='k'\n",
    "        )    \n",
    "    \n",
    "    for j, name in enumerate(chain_names):\n",
    "        ax[i].plot(_b_targets[:, j*3 + dim[0]], _b_targets[:, j*3 + dim[1]], 'rx', color='orangered')\n",
    "    ax[i].plot(_com[0, dim[0]], _com[0, dim[1]], 'bx')\n",
    "    #ax[i].set_xlim([-.7, .7])\n",
    "    #x[i].set_ylim([-0.1, 1.2])\n",
    "#plt.savefig('data/talos_config.png')\n",
    "plt.show()  \n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "fig, ax = plt.subplots(ncols=1, figsize=(12,8))\n",
    "dim = [1, 2]\n",
    "chain.plot(\n",
    "        _links, feed_dict={}, ax=ax,\n",
    "        dim=dim, alpha=0.2, color='k'\n",
    "    )    \n",
    "\n",
    "for j, name in enumerate(chain_names):\n",
    "    ax.plot(_b_targets[:, j*3 + dim[0]], _b_targets[:, j*3 + dim[1]], 'rx', color='orangered')\n",
    "ax.plot(_com[0, dim[0]], _com[0, dim[1]], 'bx')\n",
    "ax.set_xlim([-.9, .7])\n",
    "ax.set_ylim([-0.1, 1.6])\n",
    "plt.axis('off')\n",
    "plt.savefig('data/talos_config6.png', bbox_inches='tight', pad_inches=0)\n",
    "plt.show()  \n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for sample in _samples_q:\n",
    "    set_q_std(get_pb_config(sample),True)\n",
    "    print(sample[2:9])\n",
    "    input()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Use it for Projection, IK and Inverse Kinematics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Pybullet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pybullet as p\n",
    "import pybullet_data\n",
    "from utils import *\n",
    "from scipy.optimize import fmin_bfgs\n",
    "from costs import *\n",
    "from robot import *\n",
    "from scipy.optimize import fmin_bfgs\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "physics_client_id = p.connect(p.GUI)\n",
    "\n",
    "p.setPhysicsEngineParameter(enableFileCaching=0)\n",
    "p.setAdditionalSearchPath(pybullet_data.getDataPath())\n",
    "p.configureDebugVisualizer(p.COV_ENABLE_GUI,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.resetSimulation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load in pybullet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load robot\n",
    "robot_urdf = rl.datapath + '/urdf/talos_reduced.urdf';\n",
    "robot_id = p.loadURDF(fileName=robot_urdf)\n",
    "dof = p.getNumJoints(robot_id)\n",
    "\n",
    "#load plane\n",
    "plane_id = p.loadURDF('plane.urdf')\n",
    "p.resetBasePositionAndOrientation(plane_id, (0,0,0), np.array([0,0,0,1]))\n",
    "\n",
    "#set default visualization function\n",
    "set_q_std = partial(set_q,robot_id, pb_joint_indices, set_base=True)\n",
    "set_q_std(q0Complete)\n",
    "vis_traj_std = partial(vis_traj, vis_func = set_q_std)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "save_screenshot(200,200,800, 1000, 'data/task5.png', False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define frame indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pb_frame_names = [p.getJointInfo(robot_id,i)[1] for i in range(dof)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pb_lh_frame_id = pb_frame_names.index(b'gripper_left_joint')\n",
    "pb_rh_frame_id = pb_frame_names.index(b'gripper_right_joint')\n",
    "pb_lf_frame_id = pb_frame_names.index(b'leg_left_sole_fix_joint')\n",
    "pb_rf_frame_id = pb_frame_names.index(b'leg_right_sole_fix_joint')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load from pinocchio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "robot_urdf = rl.datapath + '/urdf/talos_reduced.urdf';\n",
    "rmodel = pin.buildModelFromUrdf(robot_urdf , pin.JointModelFreeFlyer())\n",
    "rdata = rmodel.createData()\n",
    "\n",
    "robot_joint_limits = np.vstack([rmodel.lowerPositionLimit, rmodel.upperPositionLimit])\n",
    "\n",
    "pin_frame_names = [f.name for f in rmodel.frames]\n",
    "lh_frame_id = rmodel.getFrameId('gripper_left_joint')\n",
    "rh_frame_id = rmodel.getFrameId('gripper_right_joint')\n",
    "lf_frame_id = rmodel.getFrameId('leg_left_sole_fix_joint')\n",
    "rf_frame_id = rmodel.getFrameId('leg_right_sole_fix_joint')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define target poses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#left foot\n",
    "pos_lf, ori_lf = computePose(rmodel,rdata,lf_frame_id,q0Complete)\n",
    "rpy_lf = mat2euler(ori_lf)\n",
    "pose_lf_ref = np.concatenate([pos_lf, rpy_lf])\n",
    "#right foot\n",
    "pos_rf, ori_rf = computePose(rmodel,rdata,rf_frame_id,q0Complete)\n",
    "rpy_rf = mat2euler(ori_rf)\n",
    "pose_rf_ref = np.concatenate([pos_rf, rpy_rf])\n",
    "#left hand\n",
    "pos_lh, ori_lh = computePose(rmodel,rdata,lh_frame_id,q0Complete)\n",
    "pose_lh_ref = np.concatenate([np.array([0.3,0.2, 0.4]), np.array([0,-np.pi/2,0.])])\n",
    "#right hand\n",
    "pos_rh, ori_rh = computePose(rmodel,rdata,rh_frame_id,q0Complete)\n",
    "rpy_rh = mat2euler(ori_rh)\n",
    "pose_rh_ref = np.concatenate([pos_rh, rpy_rh])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TalosIKSolver():\n",
    "    def __init__(self, cost):\n",
    "        self.cost = cost\n",
    "\n",
    "    def __call__(self, xk):\n",
    "        if False not in self.cost.feasibles:\n",
    "            # print('Stop at iteration!' + str(self.cost.nfev))\n",
    "            raise Exception\n",
    "\n",
    "    def project(self, q, target_pose, ftol=1e-12, gtol=1e-12, disp=0, maxiter=300):\n",
    "        # update the variables\n",
    "        self.cost.reset_iter()\n",
    "        self.cost.costs['posture'].cost.desired_posture = q.copy()\n",
    "\n",
    "        self.cost.costs['rh_pose'].cost.desired_pose[:3] = target_pose[0:3]\n",
    "        self.cost.costs['lh_pose'].cost.desired_pose[:3] = target_pose[3:6]\n",
    "        self.cost.costs['rf_pose'].cost.desired_pose[:3] = target_pose[6:9]\n",
    "        self.cost.costs['lf_pose'].cost.desired_pose[:3] = target_pose[9:]\n",
    "        \n",
    "        status = False\n",
    "        try:\n",
    "            res = minimize(self.cost.calc, q, method='l-bfgs-b', jac=self.cost.calcDiff, callback=self.__call__,\n",
    "                           options={'ftol': ftol, 'gtol': gtol, 'disp': disp, 'maxiter': maxiter})\n",
    "        except:\n",
    "            # Optimization manage to get solution\n",
    "            status = True\n",
    "        res = {'stat': status, 'q': self.cost.qs[-1], 'qs': self.cost.qs, 'nfev': self.cost.nfev,\n",
    "               'feval': self.cost.feval}\n",
    "        return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define IK solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rh_cost = CostFrameRPYFloatingBase(rmodel, rdata, pose_rh_ref,rh_frame_id, sel_vector=np.array([1,1,1,0,0,0]))\n",
    "lh_cost = CostFrameRPYFloatingBase(rmodel, rdata, pose_lh_ref,lh_frame_id, sel_vector=np.array([1,1,1,0,0,0]))\n",
    "lf_cost = CostFrameRPYFloatingBase(rmodel, rdata, pose_lf_ref,lf_frame_id, sel_vector=np.array([1,1,1,1,1,1]))\n",
    "rf_cost = CostFrameRPYFloatingBase(rmodel, rdata, pose_rf_ref,rf_frame_id, sel_vector=np.array([1,1,1,1,1,1]))\n",
    "bound_cost = CostBound(robot_joint_limits)\n",
    "posture_cost = CostPosture(rmodel, rdata, q0Complete)\n",
    "com_bounds = np.array([[-0.1,-0.1,0.6],[0.1, 0.1, 1.1]])\n",
    "cost_com_bounds = CostCOMBounds(rmodel, rdata, com_bounds)\n",
    "\n",
    "cost_sum2 = CostSum()\n",
    "cost_sum2.addCost(rh_cost, 20., 'rh_pose', 1e-3)\n",
    "cost_sum2.addCost(lh_cost, 20., 'lh_pose', 1e-3)\n",
    "cost_sum2.addCost(lf_cost, 20., 'lf_pose', 1e-5)\n",
    "cost_sum2.addCost(rf_cost, 20.,'rf_pose', 1e-5)\n",
    "cost_sum2.addCost(bound_cost, 10., 'com_limit', 1e-4)\n",
    "cost_sum2.addCost(cost_com_bounds, 10., 'joint_limit', 1e-4)\n",
    "cost_sum2.addCost(posture_cost, .01, 'posture', 1e3)\n",
    "\n",
    "robot_ik_solver = TalosIKSolver(cost_sum2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pose_rf_ref"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try IK Solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define standard sampler\n",
    "base_sampler = sampler(com_bounds.copy())\n",
    "joint_sampler = sampler(robot_joint_limits[:,7:])\n",
    "rob_sampler = talos_sampler(base_sampler, np.array([0,0,0,1]), joint_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_pose = np.concatenate([pose_rh_ref[:3], pose_lh_ref[:3], pose_rf_ref[:3], pose_lf_ref[:3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=4, suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_pose = np.array([ 0.2139, -0.4009,  0.7583,  0.3   ,  0.2   ,  0.4   , 0.1088,\n",
    "       -0.0852, -0.    , -0.0088,  0.0848, -0.    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = rob_sampler.sample()[0]\n",
    "set_q_std(q)\n",
    "input()\n",
    "res = robot_ik_solver.project(q, target_pose, disp=1)\n",
    "set_q_std(res['q'])\n",
    "print(res['stat'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using GAN sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GANSampler():\n",
    "    def __init__(self, target_sampler):\n",
    "        self.target_sampler = target_sampler\n",
    "    \n",
    "    def sample(self,N = 1, _poses = None, var = 1., idx_input = None):\n",
    "        if _poses is None:\n",
    "            _poses = self.target_sampler.sample(N)\n",
    "        self.poses = _poses\n",
    "        _foot_poses = np.tile(np.concatenate([pose_rf_ref[:3], pose_lf_ref[:3]]), (N,1))\n",
    "        _targets = np.hstack([_poses, _foot_poses])\n",
    "        feed_dict={batch_size: N*N_net, batch_target: _targets, eps_var:var}\n",
    "        feed_dict[batch_foot_ori] = _batch_foot_ori\n",
    "\n",
    "        _samples_q = sess.run([samples_q],feed_dict)\n",
    "        _samples_q = _samples_q[0]\n",
    "        print(_samples_q.shape)\n",
    "        qnew = []\n",
    "        for i in range(N):\n",
    "            #samples from N_net networks\n",
    "            if idx_input is None:\n",
    "                idx = np.random.randint(N_net)\n",
    "            else:\n",
    "                idx = idx_input\n",
    "            q = _samples_q[idx*N + i]\n",
    "            qnew += [get_pb_config(q)]\n",
    "        return np.array(qnew)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "gan_sampler = GANSampler(target_sampler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Try GAN sampler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#q = gan_sampler.sample(_poses = np.array([[-0.2, -0.3, 1.]]))[0]\n",
    "q = gan_sampler.sample()[0]\n",
    "set_q_std(q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Try random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_samples = target_sampler.sample(N = 10)\n",
    "samples = gan_sampler.sample(_poses = target_samples, N=len(target_samples), var=0.1)\n",
    "for i in range(10):\n",
    "    set_q_std(samples[i])\n",
    "    p.resetBasePositionAndOrientation(ball_id, target_samples[i], (0,0,0,1))\n",
    "    input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_animation(qs,targets, filename='data/videos.mp4'):\n",
    "    for i,q in enumerate(qs):\n",
    "        p.resetBasePositionAndOrientation(ball_id, targets[i], (0,0,0,1))\n",
    "        set_q_std(q)\n",
    "        save_screenshot(200, 200, 800, 1000, 'data/temp'+str(i)+'.png', to_show=False)\n",
    "    #make into videos\n",
    "    os.system('ffmpeg -r 25 -start_number 0 -i data/temp%d.png -c:v libx264 -r 30 -pix_fmt yuv420p ' + filename)\n",
    "    os.system('rm data/temp*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_animation(qs, ps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare the IK solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = data_target[:2000,:3]\n",
    "samples = gan_sampler.sample(N=2000, _poses=targets, var = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10\n",
    "data = dict()\n",
    "for m in range(len(methods)):\n",
    "    comp_times = []\n",
    "    success = []\n",
    "    fevals = []\n",
    "    for i in range(N):\n",
    "        idx = i\n",
    "        if method_names[m] == 'GAN':\n",
    "            q = samples[idx]\n",
    "        else:\n",
    "            q = rob_sampler.sample().flatten()\n",
    "        tic = time.time()\n",
    "        robot_ik_solver.cost.costs['rh_pose'].cost.desired_pose[:3] = targets[i]\n",
    "        res = robot_ik_solver.project(q)\n",
    "        toc = time.time()\n",
    "        comp_times += [toc-tic]\n",
    "        success += [res['stat']]\n",
    "        fevals += [res['nfev']]\n",
    "        data[method_names[m]] = [comp_times, success, fevals]\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in range(len(methods[:2])):\n",
    "    print('& ' + method_names[m], end=' ')\n",
    "    comp_times, success, fevals = data[method_names[m]]\n",
    "    comp_times = np.array(comp_times)\n",
    "    fevals = np.array(fevals)\n",
    "\n",
    "    print('& {0:.1f} &  {1:.1f} $\\pm$ {2:.1f} &  {3:.1f} $\\pm$ {4:.1f} &  {5:.1f} $\\pm$ {6:.1f}'.format(np.sum(success)*100./N, np.mean(comp_times)*1000, np.std(comp_times)*1000, np.mean(comp_times[success])*1000, np.std(comp_times[success])*1000,np.mean(fevals[success]), np.std(fevals[success])), end = ''),\n",
    "    print('\\\\\\\\ ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,_,left_box_id = create_primitives(p.GEOM_BOX, halfExtents=[0.25/2, 0.13/2, 0.01/2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.resetBasePositionAndOrientation(left_box_id, (pos_lf), (0,0,0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,_,right_box_id = create_primitives(p.GEOM_BOX, halfExtents=[0.25/2, 0.13/2, 0.01/2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.resetBasePositionAndOrientation(right_box_id, (pos_rf), (0,0,0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,_,right_ball_id = create_primitives(radius=0.1)\n",
    "_,_,left_ball_id = create_primitives(radius=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for target in targets:\n",
    "    q = rob_sampler.sample()[0]\n",
    "    res = robot_ik_solver.project(q, target)\n",
    "    p.resetBasePositionAndOrientation(right_ball_id, (target[:3]), (0,0,0,1))\n",
    "    p.resetBasePositionAndOrientation(left_ball_id, (target[3:6]), (0,0,0,1))\n",
    "    p.resetBasePositionAndOrientation(right_box_id, (target[6:9]), (0,0,0,1))\n",
    "    p.resetBasePositionAndOrientation(left_box_id, (target[9:]), (0,0,0,1))\n",
    "    set_q_std(res['q'])\n",
    "    print(res['stat'])\n",
    "    input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = get_target_new_batch(_batch_size=30000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "threshold = 0.05\n",
    "for i in range(15000):\n",
    "    print('Iteration : ' + str(i))\n",
    "    q = rob_sampler.sample()[0]\n",
    "    ress = robot_ik_solver.project(q, targets[i])\n",
    "    if ress['stat']:\n",
    "        data += [ress['q']]\n",
    "        \n",
    "    if i%100 == 0:\n",
    "        clear_output()\n",
    "        \n",
    "data = np.array(data)\n",
    "\n",
    "data_tf = []\n",
    "for d in data:\n",
    "    data_tf += [get_tf_config(d)]\n",
    "data_tf = np.array(data_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('data_two_feet_moved_manual.npy',data_tf)\n",
    "#data = np.load('data_two_feet_manual.npy')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
