{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2D robot examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('lib')\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.compat.v1 as tf1\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import OrderedDict\n",
    "import tf_robot_learning as rl\n",
    "import tf_robot_learning.distributions as ds\n",
    "import os, time\n",
    "from tf_robot_learning import kinematic as tk\n",
    "\n",
    "from IPython.core import display\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "sess = tf1.InteractiveSession()\n",
    "tf1.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Robot():\n",
    "    def __init__(self,l1, l2):\n",
    "        self.l1 = l1\n",
    "        self.l2 = l2\n",
    "        self.theta1 = 0.\n",
    "        self.theta2 = 0.\n",
    "        self.obstacles = []\n",
    "        self.R = np.array([[np.cos(np.pi/2), -np.sin(np.pi/2)],[np.sin(np.pi/2), np.cos(np.pi/2)]])\n",
    "        \n",
    "    def set_dof(self,theta):\n",
    "        self.theta1 = theta[0]\n",
    "        self.theta2 = theta[1]\n",
    "        \n",
    "    def rotate90(self,vec):\n",
    "        return np.dot(self.R, vec)\n",
    "    \n",
    "    def add_obstacle(self, x, y, r):\n",
    "        obstacle = dict()\n",
    "        obstacle['rad'] = r\n",
    "        obstacle['pos'] = np.array([x,y])\n",
    "        self.obstacles += [obstacle]\n",
    "        \n",
    "    def check_collision_single(self, obstacle):    \n",
    "        c = obstacle['pos'][:,None]\n",
    "        r = obstacle['rad']\n",
    "        b1 = c - self.p0\n",
    "        b2 = c - self.p1\n",
    "        self.res1 = np.linalg.solve(self.A1,b1)\n",
    "        self.res2 = np.linalg.solve(self.A2,b2)\n",
    "        if self.res1[0] >= 0. and self.res1[0] <= 1.:\n",
    "            if np.abs(self.res1[1]) <= r:\n",
    "                return True\n",
    "        else:\n",
    "            if np.linalg.norm(self.p0-c) < r or np.linalg.norm(self.p1-c) < r:\n",
    "                return True\n",
    "        \n",
    "        if self.res2[0] >= 0. and self.res2[0] <= 1.:\n",
    "            if np.abs(self.res2[1]) <= r:\n",
    "                return True\n",
    "        else:\n",
    "            if np.linalg.norm(self.p1-c) < r or np.linalg.norm(self.p2-c) < r:\n",
    "                return True\n",
    "            \n",
    "        return False\n",
    "        \n",
    "        \n",
    "    def normalize(self,vec):\n",
    "        return vec/np.linalg.norm(vec)\n",
    "        \n",
    "    def check_collision(self):\n",
    "        self.p0 = np.array([0.,0.])[:,None]\n",
    "        self.p1 = np.array([self.l1*np.cos(self.theta1),self.l1*np.sin(self.theta1)])[:,None]\n",
    "        self.p2 = np.array([self.p1[0,0] + self.l2*np.cos(self.theta1+self.theta2),self.p1[1,0] + self.l2*np.sin(self.theta1+self.theta2)])[:,None]\n",
    "        self.v1 = self.normalize(self.rotate90(self.p1-self.p0))\n",
    "        self.v2 = self.normalize(self.rotate90(self.p2-self.p1))\n",
    "        self.A1 = np.hstack([self.p1-self.p0, -self.v1])\n",
    "        self.A2 = np.hstack([self.p2-self.p1, -self.v2])\n",
    "        \n",
    "        for obstacle in self.obstacles:\n",
    "            if self.check_collision_single(obstacle):\n",
    "                return True\n",
    "            \n",
    "        return False\n",
    "        \n",
    "        \n",
    "        \n",
    "    def plot(self):\n",
    "        x = [0., self.l1*np.cos(self.theta1), self.l1*np.cos(self.theta1) + self.l2*np.cos(self.theta1+ self.theta2)]\n",
    "        y = [0., self.l1*np.sin(self.theta1), self.l1*np.sin(self.theta1) + self.l2*np.sin(self.theta1+ self.theta2)]\n",
    "        fig, ax = plt.subplots(nrows = 1, figsize = (6,6))\n",
    "        plt.plot(x,y,'b',linewidth=5)\n",
    "        plt.plot(x[:-1],y[:-1],'oy',markersize=3 )\n",
    "        for obstacle in self.obstacles:\n",
    "            r = obstacle['rad']\n",
    "            p = obstacle['pos']\n",
    "            circle = plt.Circle(p, r, color='r')\n",
    "            ax.add_artist(circle)\n",
    "            \n",
    "        #add base\n",
    "        rect = patches.Rectangle((-0.35,-0.35),0.7,0.7,linewidth=1,edgecolor='g',facecolor='g')\n",
    "        ax.add_patch(rect)\n",
    "        ax.set_xlim([-6,6])\n",
    "        ax.set_ylim([-6,6])\n",
    "        #ax.axis('equal')\n",
    "        ax.set(xlim=(-2*self.l1-2*self.l2,2*self.l1+2*self.l2), ylim=( -2*self.l1-2*self.l2,2*self.l1+2*self.l2))\n",
    "        return ax\n",
    "        \n",
    "    def sample_state(self, N=1):\n",
    "        samples = []\n",
    "        samples_status = []\n",
    "        for i in range(N):\n",
    "            sample = np.random.rand(2)*np.pi*2\n",
    "            self.set_dof(sample)\n",
    "            sample_status = self.check_collision()\n",
    "            samples.append(sample)\n",
    "            samples_status.append(sample_status)\n",
    "    \n",
    "        return np.array(samples), np.array(samples_status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.patches as patches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('data/2dparams.npy','rb')\n",
    "params = np.load(f,allow_pickle=True).tolist()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rob = Robot(params['lengths'][0],params['lengths'][1])\n",
    "for obs in params['obstacles']:\n",
    "    rob.add_obstacle( obs['pos'][0], obs['pos'][1],obs['rad'])\n",
    "\n",
    "rob.set_dof([0.9,1.])\n",
    "ax = rob.plot()\n",
    "ax.set_xlim([-6,6])\n",
    "ax.set_ylim([-6,6])\n",
    "ax.set_xlabel('x')\n",
    "ax.set_xlabel('y')\n",
    "ax.set_aspect('equal')\n",
    "ax.set_title('2D robot', fontsize = 20)\n",
    "plt.savefig('data/2drobot.png', bbox_inches='tight', pad_inches=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('data/2dsamples.npy','rb')\n",
    "data = np.load(f, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load kinematic chain "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "urdf = tk.urdf_from_file(rl.datapath +\n",
    "                         '/urdf/panda_arm_gripper.urdf');\n",
    "chain = tk.kdl_chain_from_urdf_model(\n",
    "    urdf, tip='panda_leftfinger_tip'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf_robot_learning import planar_robots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "robot = planar_robots.TwoJointRobot(ls=np.array(params['lengths']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "fs = [\n",
    "    lambda q : robot.xs(q)[:, -1],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_eval = tf1.placeholder(tf.float32, (None,robot.dof))\n",
    "x_eval = robot.xs(q_eval)\n",
    "\n",
    "def q_augmented(q):\n",
    "    # return tf.concat([q, fs[0](q)], axis=1)\n",
    "    return tf.concat([q, tf.sin(q), tf.cos(q)], axis=1)\n",
    "\n",
    "q_augmented_eval = q_augmented(q_eval)\n",
    "q_target_eval = fs[0](q_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "data_augmented = q_augmented_eval.eval({q_eval: data})\n",
    "data_target = q_target_eval.eval({q_eval: data})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def get_batch(_batch_size=30, cut=None, augmented=True):\n",
    "    if cut is not None:    \n",
    "        idx = np.random.randint(\n",
    "            0, cut, _batch_size)\n",
    "    else:\n",
    "        idx = np.random.randint(\n",
    "            0, data_augmented.shape[0]-1, _batch_size)\n",
    "    if augmented: return data_augmented[idx]\n",
    "    else: return data[idx]\n",
    "    \n",
    "def get_target_batch(_batch_size=30, cut=None):\n",
    "    if cut is not None: idx = np.random.randint( 0, cut, _batch_size)\n",
    "    else: idx = np.random.randint(0, data_augmented.shape[0]-1, _batch_size)\n",
    "    return data_target[idx]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "rate = tf1.placeholder(tf.float32, ())\n",
    "\n",
    "# Network Parameters\n",
    "joint_dim = robot.dof # MNIST images are 28x28 pixels\n",
    "latent_dim = 3\n",
    "\n",
    "target_dim = 2\n",
    "#target_latent_dim = 2\n",
    "\n",
    "augmented_dim = data_augmented.shape[-1]\n",
    "\n",
    "N_net = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "gen_nn = rl.nn.MLP(\n",
    "    n_input=latent_dim+target_dim, n_output=joint_dim, n_hidden=[200, 200],\n",
    "    act_fct=tf.nn.relu, batch_size_svi=N_net\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discr_nn = rl.nn.MLP(\n",
    "    n_input=augmented_dim, n_output=1, n_hidden=[100, 100],\n",
    "    act_fct=tf.nn.relu\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_x = tf1.placeholder(tf.float32, (None, augmented_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target parameters to feed generator\n",
    "batch_target = tf1.placeholder(tf.float32, (None, target_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = tf1.placeholder(tf.int32, ())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Sampler: Normal (gaussian) random distribution\n",
    "# eps = tf.random.normal([batch_size, latent_dim], \n",
    "    # dtype=tf.float32, mean=0., stddev=1.0, name='epsilon')\n",
    "eps = tf.random.normal([tf.cast(batch_size/N_net, tf.int32), latent_dim], \n",
    "    dtype=tf.float32, mean=0., stddev=1.0, name='epsilon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to feed main generator noise + parameters samples\n",
    "eps_conc = tf.concat([eps, batch_target], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reshape(gen_nn.pred(eps_conc), (-1, joint_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# samples_q = gen_nn.pred(eps_conc) + tf.constant([4., 4.])[None]\n",
    "samples_q = tf.reshape(gen_nn.pred(eps_conc) + tf.constant(\n",
    "    np.random.normal(4., 4., (N_net, 1, 2)), dtype=tf.float32) , (-1, joint_dim)) \n",
    "samples_x = robot.xs(samples_q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Another evaluation to feed custom noise "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "eps_feed = tf1.placeholder(tf.float32, (None, latent_dim))\n",
    "samples_q_feed = gen_nn.pred(eps_feed)\n",
    "samples_x_feed = robot.xs(samples_q_feed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "d_fake = discr_nn.pred(q_augmented(samples_q))[:, 0]\n",
    "d_true = discr_nn.pred(batch_x)[:, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discriminative loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_d = tf.nn.sigmoid_cross_entropy_with_logits(labels=tf.ones_like(d_true), logits=d_true) + \\\n",
    "        tf.nn.sigmoid_cross_entropy_with_logits(labels=tf.zeros_like(d_fake), logits=d_fake)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generative loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "    labels=tf.ones_like(d_fake), logits=d_fake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "loss = tf.reduce_sum(loss)\n",
    "loss_d = tf.reduce_sum(loss_d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a Gaussian distribution that should be tracked by the system\n",
    "p_target_std = tf1.placeholder(tf.float32, ()) \n",
    "p_target = ds.MultivariateNormalFullCovariance(\n",
    "    # batch_target, p_target_std**2 * tf.eye(2)\n",
    "    tf.reshape(tf.ones((N_net, 1, 1)) * batch_target[None], (-1, target_dim)), p_target_std**2 * tf.eye(2)\n",
    ")\n",
    "samples_target_proj = fs[0](samples_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_target = tf.reduce_sum(-p_target.log_prob(samples_target_proj))\n",
    "# loss_target = tf.reduce_sum(tf.norm(batch_target-samples_target_proj,axis=1))\n",
    "lmbda_target = tf1.placeholder(tf.float32, ())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overall loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_gen = loss + lmbda_target * loss_target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "rate = tf1.placeholder(tf.float32, ())\n",
    "opt = tf1.train.AdamOptimizer\n",
    "\n",
    "optimizer = opt(learning_rate=rate)\n",
    "optimizer_d = opt(learning_rate=rate)\n",
    "\n",
    "train = optimizer.minimize(loss_gen, var_list=gen_nn.vec_weights)\n",
    "train_d = optimizer_d.minimize(loss_d, var_list=discr_nn.vec_weights)\n",
    "\n",
    "# Initialize the variables (i.e. assign their default value)\n",
    "init = tf1.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "_batch_size = 100\n",
    "alpha = .3\n",
    "\n",
    "for i in range(10000):\n",
    "    try:\n",
    "        for j in range(5):\n",
    "            # train discriminative_network\n",
    "            _x = get_batch( _batch_size=_batch_size)\n",
    "            feed_dict = {\n",
    "                lmbda_target: 0.1,\n",
    "                p_target_std: 1.,\n",
    "                batch_x: _x,\n",
    "                batch_size: _batch_size,\n",
    "                rate : 0.002 * alpha\n",
    "            }\n",
    "            feed_dict[batch_target] = get_target_batch( _batch_size=int(_batch_size/N_net))\n",
    "            _ = sess.run([train_d], feed_dict=feed_dict)\n",
    "        \n",
    "        feed_dict[rate] = 0.001 * alpha\n",
    "        # train generative_network\n",
    "        _, _loss, _loss_target, _loss_d = sess.run(\n",
    "            [train, loss, loss_target, loss_d], feed_dict=feed_dict)\n",
    "        \n",
    "        if not i % 10:\n",
    "            display.clear_output(wait=True)\n",
    "            print('Step %i\\t, Loss gen: %f\\t, loss discr %f, loss target %f' % (i, _loss, _loss_d, _loss_target))\n",
    "    except KeyboardInterrupt:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "n = 5000\n",
    "fig, ax = plt.subplots(ncols=3)\n",
    "fig.set_size_inches(12,4)\n",
    "_targets = get_target_batch(cut=3000, _batch_size=int(n/N_net))\n",
    "\n",
    "# _samples_q = samples_q.eval({batch_size: n, batch_target: _targets})\n",
    "_samples_q = samples_q.eval({batch_size: n, batch_target: _targets})\n",
    "# _samples_xs = sess.run(x_eval, {q_eval: _samples_q})\n",
    "\n",
    "#plt.plot(samples_invalid[:,0],samples_invalid[:,1], 'oy')\n",
    "\n",
    "ax[0].plot(data[:,0],data[:,1],'o',alpha=0.3)\n",
    "ax[0].plot(_samples_q[:,0],_samples_q[:,1],'bo',alpha=0.1)\n",
    "ax[1].plot(_samples_q[:,0],_samples_q[:,1],'bo',alpha=0.1)\n",
    "ax[2].plot(data[:,0],data[:,1],'o',alpha=0.3)\n",
    "\n",
    "for a in ax:\n",
    "    a.set_aspect('equal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('2d_'+str(N_net)+'.npy', data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('2d_'+str(N_net)+'.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, figsize = (6,6))\n",
    "ax.plot(data[:,0],data[:,1],'o',alpha=0.3)\n",
    "ax.plot(_samples_q[:,0],_samples_q[:,1],'bx',alpha=0.3)\n",
    "ax.set_aspect('equal')\n",
    "ax.set_xlabel(r'$\\bf{\\theta_1}$', fontsize=20)\n",
    "ax.set_ylabel(r'$\\bf{\\theta_2}$', fontsize=20)\n",
    "ax.set_xlim([0,6.6])\n",
    "ax.set_ylim([0,6.6])\n",
    "ax.set_title(r'$N_{net}$ = ' + str(N_net), fontsize=20)\n",
    "plt.savefig('data/2d_' + str(N_net) + '.png', bbox_inches='tight', pad_inches=0)\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "hide_input": false,
  "kernelspec": {
   "display_name": "PyCharm (optimal_control)",
   "language": "python",
   "name": "pycharm-688c58dd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
